trainer:
  gradient_clip_val: 10.0
  gradient_clip_algorithm: value
  max_steps: 15000

  logger:
    # class_path: pytorch_lightning.loggers.WandbLogger
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      entity: team-mcomunita-qmul
      project: nnlinafx-PARAM
      name: gb_GB-PARAM-FUZZ-RNL_lr.1_lrm1_td.5_fd.5_phinv
      save_dir: logs-scratch-02/multidrive-ffuzz/GB-PARAM-FUZZ-RNL/gb_GB-PARAM-FUZZ-RNL_lr.1_lrm1_td.5_fd.5_phinv # dir needs to already exist
      # save_dir: logs/test
      group: Multidrive-FFuzz_GB-PARAM-FUZZ-RNL
      tags: ["Multidrive-FFuzz", "GB-PARAM-FUZZ-RNL"]

  callbacks:
    # üéµ NablAFx Audio Logging - Replaces built-in log_audio()
    - class_path: nablafx.callbacks.AudioLoggingCallback
      init_args:
        log_every_n_steps: 3000 # Matches typical log_media_every_n_steps
        sample_rate: 48000
        max_samples_per_batch: 3
        log_test_batches: 10
        log_input_target_once: true

    # üìä NablAFx Metrics Logging - Replaces built-in compute_and_log_metrics()
    - class_path: nablafx.callbacks.MetricsLoggingCallback
      init_args:
        log_on_step: false
        log_on_epoch: true
        sync_dist: true

    # üéõÔ∏è NablAFx Frequency Response - Replaces built-in log_frequency_response()
    - class_path: nablafx.callbacks.FrequencyResponseCallback
      init_args:
        log_on_train_start: false
        log_on_train_end: false
        log_on_test_end: true
        log_every_n_epochs: 25

    # üéØ NablAFx FAD Computation - Replaces built-in compute_and_log_fad()
    - class_path: nablafx.callbacks.FADComputationCallback
      init_args:
        compute_on_train_end: true
        compute_on_test_end: true
        compute_every_n_epochs: 10
        models: ["vggish", "pann", "clap", "afx-rep"]
        checkpoint_dir: "checkpoints_fad"

    # üé® NablAFx Parameter Visualization - For gray-box models
    - class_path: nablafx.callbacks.ParameterVisualizationCallback
      init_args:
        log_on_train_start: true
        log_on_validation: true
        log_on_test: true
        log_test_batches: 10
        max_samples_per_batch: 2

    # ‚ö° Standard Lightning Callbacks
    # - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    - class_path: lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint
      init_args:
        save_last: true
        save_top_k: 1
        monitor: loss/val/tot
        every_n_train_steps: 100
        filename: "{epoch}-{step}"
    # - class_path: pytorch_lightning.callbacks.ModelSummary
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: 2
    # - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    # - class_path: pytorch_lightning.callbacks.EarlyStopping
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: "loss/val/tot"
        patience: 50
        verbose: true
